{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Automatidata project**\n",
    "**Course 6 - The Nuts and bolts of machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ttxbfHXzB4e"
   },
   "source": [
    "You are a data professional in a data analytics firm called Automatidata. Their client, the New York City Taxi & Limousine Commission (New York City TLC), was impressed with the work you have done and has requested that you build a machine learning model to predict if a customer will not leave a tip. They want to use the model in an app that will alert taxi drivers to customers who are unlikely to tip, since drivers depend on tips.\n",
    "\n",
    "A notebook was structured and prepared to help you in this project. Please complete the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# Course 6 End-of-course project: Build a machine learning model\n",
    "\n",
    "In this activity, you will practice using tree-based modeling techniques to predict on a binary target class.  \n",
    "<br/>   \n",
    "\n",
    "**The purpose** of this model is to find ways to generate more revenue for taxi cab drivers.  \n",
    "  \n",
    "**The goal** of this model is to predict whether or not a customer is a generous tipper.  \n",
    "<br/>  \n",
    "\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** Ethical considerations \n",
    "* Consider the ethical implications of the request \n",
    "\n",
    "* Should the objective of the model be adjusted?\n",
    "\n",
    "**Part 2:** Feature engineering\n",
    "\n",
    "* Perform feature selection, extraction, and transformation to prepare the data for modeling\n",
    "\n",
    "**Part 3:** Modeling\n",
    "\n",
    "* Build the models, evaluate them, and advise on next steps\n",
    "\n",
    "Follow the instructions and answer the questions below to complete the activity. Then, complete an Executive Summary using the questions listed on the PACE Strategy Document. \n",
    "\n",
    "Be sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzDjfCSLf6Jq"
   },
   "source": [
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "# **PACE stages**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5g1A74r0ow_"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## PACE: Plan \n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Plan stage.\n",
    "\n",
    "In this stage, consider the following questions:\n",
    "\n",
    "1.   What are you being asked to do?\n",
    "\n",
    "\n",
    "2.   What are the ethical implications of the model? What are the consequences of your model making errors?\n",
    "  *   What is the likely effect of the model when it predicts a false negative (i.e., when the model says a customer will give a tip, but they actually won't)?\n",
    "  \n",
    "  *   What is the likely effect of the model when it predicts a false positive (i.e., when the model says a customer will not give a tip, but they actually will)?  \n",
    "  \n",
    "  \n",
    "3.   Do the benefits of such a model outweigh the potential problems?\n",
    "  \n",
    "4.   Would you proceed with the request to build this model? Why or why not?\n",
    " \n",
    "5.   Can the objective be modified to make it less problematic?\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I am being asked to build a machine learning model that predicts whether a customer will not leave a tip based on the provided data. The model will be used in an app to alert taxi drivers about customers who are unlikely to tip.\n",
    "\n",
    "2. Ethical implications include potential discrimination or bias against certain groups of customers. If the model makes errors, it could lead to unfair treatment of customers, negatively affecting their experience and potentially harming the reputation of the taxi service. In this case `will not tip = true positive`\n",
    "    - When the model predicts a false negative (i.e., predicts that a customer will give a tip, but they actually won't), the taxi drivers might provide good service or go above and beyond in the expectation of a tip. However, the customer does not leave a tip, potentially leading to disappointment and frustration on the driver's part.\n",
    "    - When the model predicts a false positive (i.e., predicts that a customer will not give a tip, but they actually will), the drivers might provide subpar service or avoid interacting with the customer. However, the customer ends up leaving a tip, leading to a missed opportunity for the driver to provide good service and potentially a negative customer experience.\n",
    "\n",
    "3. It's arguable. While the model might help drivers manage their expectations, the potential for discrimination, negative experiences, and conflicts raises serious concerns about its overall benefits.\n",
    "\n",
    "4. Proceeding with the request requires careful consideration of the ethical implications and potential harm. It might be wiser to explore alternative ways to improve customer service and driver experiences without relying solely on a predictive model that could lead to unfair treatment.\n",
    "\n",
    "5. Yes, the objective could be modified to focus on improving customer service, communication, and satisfaction for all customers, rather than singling out specific customers who might not tip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUUrVKTe4cc5"
   },
   "source": [
    "Suppose you were to modify the modeling objective so, instead of predicting people who won't tip at all, you predicted people who are particularly generous&mdash;those who will tip 20% or more? Consider the following questions:\n",
    "\n",
    "1.  What features do you need to make this prediction?\n",
    "\n",
    "2.  What would be the target variable?  \n",
    "\n",
    "3.  What metric should you use to evaluate your model? Do you have enough information to decide this now?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Features:**\n",
    "   - Features related to the trip: trip distance, fare amount, payment type, trip duration, etc.\n",
    "   - Features related to the customer: previous tipping behavior, customer rating, frequency of rides, etc.\n",
    "   - Time-related features: day of the week, time of day, etc.\n",
    "\n",
    "2. **Target Variable:**\n",
    "   - The target variable would be binary: \n",
    "       - 1 (positive class) if the customer is predicted to tip 20% or more, and \n",
    "       - 0 (negative class) otherwise.\n",
    "\n",
    "3. **Evaluation Metric:**\n",
    "   - The choice of the evaluation metric depends on the business context and priorities. Since the goal is to predict generous tippers, we would likely want to focus on **precision**. Precision measures the proportion of predicted generous tippers that are actually generous tippers. A high precision means fewer false positives, which is important in this scenario to avoid mistakenly identifying customers as generous tippers when they are not.\n",
    "\n",
    "   - However, we might also consider other metrics like recall, F1-score, and ROC-AUC depending on the trade-off between false positives and false negatives.\n",
    "\n",
    "4. **Information Needed:**\n",
    "   - To decide on the evaluation metric, we would need to know the business implications of false positives and false negatives. For example, if mistakenly labeling a non-generous tipper as generous has minimal impact but missing a genuinely generous tipper is costly, we might prioritize recall. Conversely, if avoiding mistaken identifications is more important, we'd prioritize precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**_Complete the following steps to begin:_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Vm3QEfGELS"
   },
   "source": [
    "### **Task 1. Imports and data loading**\n",
    "\n",
    "Import packages and libraries needed to build and evaluate random forest and XGBoost classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fKhnX2Puf4Bt"
   },
   "outputs": [],
   "source": [
    "# Import packages and libraries\n",
    "### YOUR CODE HERE import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# This is the function that helps plot feature importance \n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO SEE ALL COLUMNS \n",
    "# This lets us see all of the columns, preventing Juptyer from redacting them.\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeXTZ2tdbALL"
   },
   "source": [
    "Begin by reading in the data. There are two dataframes: one containing the original data, the other containing the mean durations, mean distances, and predicted fares from the previous course's project called nyc_preds_means.csv.\n",
    "\n",
    "**Note:** `Pandas` reads in the dataset as `df0`, now inspect the first five rows. As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5weTXGKqa_iG"
   },
   "outputs": [],
   "source": [
    "# RUN THE CELL BELOW TO IMPORT YOUR DATA. \n",
    "\n",
    "# Load dataset into dataframe\n",
    "df0 = pd.read_csv('2017_Yellow_Taxi_Trip_Data.csv')\n",
    "\n",
    "# Import predicted fares and mean distance and duration from previous course\n",
    "nyc_preds_means = pd.read_csv('nyc_preds_means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first few rows of `df0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30841670</td>\n",
       "      <td>2</td>\n",
       "      <td>04/15/2017 11:32:20 PM</td>\n",
       "      <td>04/15/2017 11:49:03 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  \\\n",
       "0    24870114         2   03/25/2017 8:55:43 AM   03/25/2017 9:09:47 AM   \n",
       "1    35634249         1   04/11/2017 2:53:28 PM   04/11/2017 3:19:58 PM   \n",
       "2   106203690         1   12/15/2017 7:26:56 AM   12/15/2017 7:34:08 AM   \n",
       "3    38942136         2   05/07/2017 1:17:59 PM   05/07/2017 1:48:14 PM   \n",
       "4    30841670         2  04/15/2017 11:32:20 PM  04/15/2017 11:49:03 PM   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "4                1           4.37           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "4             4           112             2         16.5    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \n",
       "0        2.76           0.0                    0.3         16.56  \n",
       "1        4.00           0.0                    0.3         20.80  \n",
       "2        1.45           0.0                    0.3          8.75  \n",
       "3        6.39           0.0                    0.3         27.69  \n",
       "4        0.00           0.0                    0.3         17.80  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first few rows of df0\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first few rows of `nyc_preds_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.616667</td>\n",
       "      <td>4.435000</td>\n",
       "      <td>15.845642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_duration  mean_distance  predicted_fare\n",
       "0      22.847222       3.521667       16.434245\n",
       "1      24.470370       3.108889       16.052218\n",
       "2       7.250000       0.881429        7.053706\n",
       "3      30.250000       3.700000       18.731650\n",
       "4      14.616667       4.435000       15.845642"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first few rows of `nyc_preds_means`\n",
    "nyc_preds_means.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the two dataframes\n",
    "\n",
    "Join the two dataframes using a method of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22699, 18), (22699, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.shape, nyc_preds_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "df0 = pd.concat([df0, nyc_preds_means], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgPRBjizg1oo"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Analyze**\n",
    "\n",
    "Consider the questions in your PACE Strategy Documentto reflect on the Analyze stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VZowX9rhU1o"
   },
   "source": [
    "### **Task 2. Feature engineering**\n",
    "\n",
    "You have already prepared much of this data and performed exploratory data analysis (EDA) in previous courses. \n",
    "\n",
    "Call `info()` on the new combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mBOSW8IDbO_d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22699 entries, 0 to 22698\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             22699 non-null  int64  \n",
      " 1   VendorID               22699 non-null  int64  \n",
      " 2   tpep_pickup_datetime   22699 non-null  object \n",
      " 3   tpep_dropoff_datetime  22699 non-null  object \n",
      " 4   passenger_count        22699 non-null  int64  \n",
      " 5   trip_distance          22699 non-null  float64\n",
      " 6   RatecodeID             22699 non-null  int64  \n",
      " 7   store_and_fwd_flag     22699 non-null  object \n",
      " 8   PULocationID           22699 non-null  int64  \n",
      " 9   DOLocationID           22699 non-null  int64  \n",
      " 10  payment_type           22699 non-null  int64  \n",
      " 11  fare_amount            22699 non-null  float64\n",
      " 12  extra                  22699 non-null  float64\n",
      " 13  mta_tax                22699 non-null  float64\n",
      " 14  tip_amount             22699 non-null  float64\n",
      " 15  tolls_amount           22699 non-null  float64\n",
      " 16  improvement_surcharge  22699 non-null  float64\n",
      " 17  total_amount           22699 non-null  float64\n",
      " 18  mean_duration          22699 non-null  float64\n",
      " 19  mean_distance          22699 non-null  float64\n",
      " 20  predicted_fare         22699 non-null  float64\n",
      "dtypes: float64(11), int64(7), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D2RvXk0kwsx"
   },
   "source": [
    "You know from your EDA that customers who pay cash generally have a tip amount of $0. To meet the modeling objective, you'll need to sample the data to select only the customers who pay with credit card. \n",
    "\n",
    "Copy `df0` and assign the result to a variable called `df1`. Then, use a Boolean mask to filter `df1` so it contains only customers who paid with credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_pmNd78plQYr"
   },
   "outputs": [],
   "source": [
    "# Subset the data to isolate only customers who paid by credit card\n",
    "df1 = df0.copy()\n",
    "\n",
    "mask = df1['payment_type'] == 1\n",
    "\n",
    "df1 = df1[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15265, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcYudtSYyMcZ"
   },
   "source": [
    "##### **Target**\n",
    "\n",
    "Notice that there isn't a column that indicates tip percent, which is what you need to create the target variable. You'll have to engineer it. \n",
    "\n",
    "Add a `tip_percent` column to the dataframe by performing the following calculation:  \n",
    "<br/>  \n",
    "\n",
    "\n",
    "$$tip\\ percent = \\frac{tip\\ amount}{total\\ amount - tip\\ amount}$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "guanzJd8zBla"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "      <th>tip_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23345809</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:34:11 PM</td>\n",
       "      <td>03/25/2017 8:42:11 PM</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>10.441351</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID   tpep_pickup_datetime  tpep_dropoff_datetime  \\\n",
       "0    24870114         2  03/25/2017 8:55:43 AM  03/25/2017 9:09:47 AM   \n",
       "1    35634249         1  04/11/2017 2:53:28 PM  04/11/2017 3:19:58 PM   \n",
       "2   106203690         1  12/15/2017 7:26:56 AM  12/15/2017 7:34:08 AM   \n",
       "3    38942136         2  05/07/2017 1:17:59 PM  05/07/2017 1:48:14 PM   \n",
       "5    23345809         2  03/25/2017 8:34:11 PM  03/25/2017 8:42:11 PM   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "5                6           2.30           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "5           161           236             1          9.0    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "5        2.06           0.0                    0.3         12.36   \n",
       "\n",
       "   mean_duration  mean_distance  predicted_fare  tip_percent  \n",
       "0      22.847222       3.521667       16.434245        0.200  \n",
       "1      24.470370       3.108889       16.052218        0.238  \n",
       "2       7.250000       0.881429        7.053706        0.199  \n",
       "3      30.250000       3.700000       18.731650        0.300  \n",
       "5      11.855376       2.052258       10.441351        0.200  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tip % col\n",
    "df1['tip_percent'] = round(df1['tip_amount']/ (df1['total_amount'] - df1['tip_amount']),3)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqb-SWfs-8Xn"
   },
   "source": [
    "Now create another column called `generous`. This will be the target variable. The column should be a binary indicator of whether or not a customer tipped ≥ 20% (0=no, 1=yes).\n",
    "\n",
    "1. Begin by making the `generous` column a copy of the `tip_percent` column.\n",
    "2. Reassign the column by converting it to Boolean (True/False).\n",
    "3. Reassign the column by converting Boolean to binary (1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nqDSe0DSGwhB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "      <th>tip_percent</th>\n",
       "      <th>generous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:55:43 AM</td>\n",
       "      <td>03/25/2017 9:09:47 AM</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>04/11/2017 2:53:28 PM</td>\n",
       "      <td>04/11/2017 3:19:58 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "      <td>0.238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>12/15/2017 7:26:56 AM</td>\n",
       "      <td>12/15/2017 7:34:08 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>05/07/2017 1:17:59 PM</td>\n",
       "      <td>05/07/2017 1:48:14 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23345809</td>\n",
       "      <td>2</td>\n",
       "      <td>03/25/2017 8:34:11 PM</td>\n",
       "      <td>03/25/2017 8:42:11 PM</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>10.441351</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID   tpep_pickup_datetime  tpep_dropoff_datetime  \\\n",
       "0    24870114         2  03/25/2017 8:55:43 AM  03/25/2017 9:09:47 AM   \n",
       "1    35634249         1  04/11/2017 2:53:28 PM  04/11/2017 3:19:58 PM   \n",
       "2   106203690         1  12/15/2017 7:26:56 AM  12/15/2017 7:34:08 AM   \n",
       "3    38942136         2  05/07/2017 1:17:59 PM  05/07/2017 1:48:14 PM   \n",
       "5    23345809         2  03/25/2017 8:34:11 PM  03/25/2017 8:42:11 PM   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "5                6           2.30           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "5           161           236             1          9.0    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "5        2.06           0.0                    0.3         12.36   \n",
       "\n",
       "   mean_duration  mean_distance  predicted_fare  tip_percent  generous  \n",
       "0      22.847222       3.521667       16.434245        0.200         1  \n",
       "1      24.470370       3.108889       16.052218        0.238         1  \n",
       "2       7.250000       0.881429        7.053706        0.199         0  \n",
       "3      30.250000       3.700000       18.731650        0.300         1  \n",
       "5      11.855376       2.052258       10.441351        0.200         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 'generous' col (target)\n",
    "df1['generous'] = df1['tip_percent'].copy()\n",
    "df1['generous'] = np.where(df1['tip_percent'] >= 0.2, 1, 0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8035\n",
       "0    7230\n",
       "Name: generous, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['generous'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddLE6KE1KeF7"
   },
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To convert from Boolean to binary, use `.astype(int)` on the column.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create day column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H27zUVIlkaxA"
   },
   "source": [
    "Next, you're going to be working with the pickup and dropoff columns.\n",
    "\n",
    "Convert the `tpep_pickup_datetime` and `tpep_dropoff_datetime` columns to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OIycxWBMkafJ"
   },
   "outputs": [],
   "source": [
    "# Convert pickup and dropoff cols to datetime\n",
    "df1['tpep_pickup_datetime'] = pd.to_datetime(df1['tpep_pickup_datetime'])\n",
    "df1['tpep_dropoff_datetime'] = pd.to_datetime(df1['tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpcM4FvNyPFY"
   },
   "source": [
    "Create a `day` column that contains only the day of the week when each passenger was picked up. Then, convert the values to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "abUvtMaYyWpD"
   },
   "outputs": [],
   "source": [
    "# Create a 'day' col\n",
    "#day_mapping = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "#df1['day'] = df1['tpep_pickup_datetime'].dt.dayofweek.map(day_mapping).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or using\n",
    "#df1['day'] = df1['tpep_pickup_datetime'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "      <th>tip_percent</th>\n",
       "      <th>generous</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-25 08:55:43</td>\n",
       "      <td>2017-03-25 09:09:47</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-11 14:53:28</td>\n",
       "      <td>2017-04-11 15:19:58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "      <td>0.238</td>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-15 07:26:56</td>\n",
       "      <td>2017-12-15 07:34:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0</td>\n",
       "      <td>friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-07 13:17:59</td>\n",
       "      <td>2017-05-07 13:48:14</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23345809</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-25 20:34:11</td>\n",
       "      <td>2017-03-25 20:42:11</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>10.441351</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0    24870114         2  2017-03-25 08:55:43   2017-03-25 09:09:47   \n",
       "1    35634249         1  2017-04-11 14:53:28   2017-04-11 15:19:58   \n",
       "2   106203690         1  2017-12-15 07:26:56   2017-12-15 07:34:08   \n",
       "3    38942136         2  2017-05-07 13:17:59   2017-05-07 13:48:14   \n",
       "5    23345809         2  2017-03-25 20:34:11   2017-03-25 20:42:11   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "5                6           2.30           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "5           161           236             1          9.0    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "5        2.06           0.0                    0.3         12.36   \n",
       "\n",
       "   mean_duration  mean_distance  predicted_fare  tip_percent  generous  \\\n",
       "0      22.847222       3.521667       16.434245        0.200         1   \n",
       "1      24.470370       3.108889       16.052218        0.238         1   \n",
       "2       7.250000       0.881429        7.053706        0.199         0   \n",
       "3      30.250000       3.700000       18.731650        0.300         1   \n",
       "5      11.855376       2.052258       10.441351        0.200         1   \n",
       "\n",
       "        day  \n",
       "0  saturday  \n",
       "1   tuesday  \n",
       "2    friday  \n",
       "3    sunday  \n",
       "5  saturday  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or using \n",
    "df1['day'] = df1['tpep_pickup_datetime'].dt.strftime('%A').str.lower()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZZhKnQrQgNM"
   },
   "source": [
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To convert to day name, use `dt.day_name()` on the column.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time of day columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwslVt8Hpu7x"
   },
   "source": [
    "Next, engineer four new columns that represent time of day bins. Each column should contain binary values (0=no, 1=yes) that indicate whether a trip began (picked up) during the following times:\n",
    "\n",
    "`am_rush` = [06:00&ndash;10:00)  \n",
    "`daytime` = [10:00&ndash;16:00)  \n",
    "`pm_rush` = [16:00&ndash;20:00)  \n",
    "`nighttime` = [20:00&ndash;06:00)  \n",
    "\n",
    "To do this, first create the four columns. For now, each new column should be identical and contain the same information: the hour (only) from the `tpep_pickup_datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "x8LFySUyprau"
   },
   "outputs": [],
   "source": [
    "am_mask = (df1['tpep_pickup_datetime'].dt.hour >= 6) & (df1['tpep_pickup_datetime'].dt.hour < 10)\n",
    "day_mask = (df1['tpep_pickup_datetime'].dt.hour >= 10) & (df1['tpep_pickup_datetime'].dt.hour < 16)\n",
    "pm_mask = (df1['tpep_pickup_datetime'].dt.hour >= 16) & (df1['tpep_pickup_datetime'].dt.hour < 20)\n",
    "night_mask = (df1['tpep_pickup_datetime'].dt.hour >= 20) | (df1['tpep_pickup_datetime'].dt.hour < 6)\n",
    "\n",
    "# Create 'am_rush' col\n",
    "df1['am_rush'] = np.where(am_mask, 1, 0)\n",
    "\n",
    "# Create 'daytime' col\n",
    "df1['daytime'] = np.where(day_mask, 1, 0)\n",
    "\n",
    "# Create 'pm_rush' col\n",
    "df1['pm_rush'] = np.where(pm_mask, 1, 0)\n",
    "\n",
    "# Create 'nighttime' col\n",
    "df1['nighttime'] = np.where(night_mask, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">**Note: My code is is so efficient that we don't need below lines.**</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDyfsTDvwORL"
   },
   "source": [
    "You'll need to write four functions to convert each new column to binary (0/1). Begin with `am_rush`. Complete the function so if the hour is between [06:00–10:00), it returns 1, otherwise, it returns 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oAE4vRz0wGtN"
   },
   "outputs": [],
   "source": [
    "# Define 'am_rush()' conversion function [06:00–10:00)\n",
    "    #==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHY1-6cIxfA6"
   },
   "source": [
    "Now, apply the `am_rush()` function to the `am_rush` series to perform the conversion. Print the first five values of the column to make sure it did what you expected it to do.\n",
    "\n",
    "**Note:** Be careful! If you run this cell twice, the function will be reapplied and the values will all be changed to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sWFojyk9xdDY"
   },
   "outputs": [],
   "source": [
    "# Apply 'am_rush' function to the 'am_rush' series\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSY6SsdK0lpn"
   },
   "source": [
    "Write functions to convert the three remaining columns and apply them to their respective series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UADnzaIjzwLG"
   },
   "outputs": [],
   "source": [
    "# Define 'daytime()' conversion function [10:00–16:00)\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ReHpKxoC1Qsx"
   },
   "outputs": [],
   "source": [
    "# Apply 'daytime()' function to the 'daytime' series\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rP-ZBOHT1WQY"
   },
   "outputs": [],
   "source": [
    "# Define 'pm_rush()' conversion function [16:00–20:00)\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "h0zWPBqr1mX4"
   },
   "outputs": [],
   "source": [
    "# Apply 'pm_rush()' function to the 'pm_rush' series\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "u5O0LPLz2CSa"
   },
   "outputs": [],
   "source": [
    "# Define 'nighttime()' conversion function [20:00–06:00)\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kLGmBXkT2RTi"
   },
   "outputs": [],
   "source": [
    "# Apply 'nighttime' function to the 'nighttime' series\n",
    "#==> ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `month` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrUmDy8U28bs"
   },
   "source": [
    "Now, create a `month` column that contains only the abbreviated name of the month when each passenger was picked up, then convert the result to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU5Zchdxgk3w"
   },
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "Refer to the [strftime cheatsheet](https://strftime.org/) for help.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month' col\n",
    "df1['month'] = df1['tpep_pickup_datetime'].dt.month_name().str[:3].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use\n",
    "#df1['month'] = df1['tpep_pickup_datetime'].dt.strftime('%b').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWbNVbngihE6"
   },
   "source": [
    "Examine the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jWxemeyl4vwQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "      <th>tip_percent</th>\n",
       "      <th>generous</th>\n",
       "      <th>day</th>\n",
       "      <th>am_rush</th>\n",
       "      <th>daytime</th>\n",
       "      <th>pm_rush</th>\n",
       "      <th>nighttime</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24870114</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-25 08:55:43</td>\n",
       "      <td>2017-03-25 09:09:47</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35634249</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-11 14:53:28</td>\n",
       "      <td>2017-04-11 15:19:58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.80</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "      <td>0.238</td>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106203690</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-15 07:26:56</td>\n",
       "      <td>2017-12-15 07:34:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0</td>\n",
       "      <td>friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38942136</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-07 13:17:59</td>\n",
       "      <td>2017-05-07 13:48:14</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.69</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23345809</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-25 20:34:11</td>\n",
       "      <td>2017-03-25 20:42:11</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>10.441351</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0    24870114         2  2017-03-25 08:55:43   2017-03-25 09:09:47   \n",
       "1    35634249         1  2017-04-11 14:53:28   2017-04-11 15:19:58   \n",
       "2   106203690         1  2017-12-15 07:26:56   2017-12-15 07:34:08   \n",
       "3    38942136         2  2017-05-07 13:17:59   2017-05-07 13:48:14   \n",
       "5    23345809         2  2017-03-25 20:34:11   2017-03-25 20:42:11   \n",
       "\n",
       "   passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                6           3.34           1                  N   \n",
       "1                1           1.80           1                  N   \n",
       "2                1           1.00           1                  N   \n",
       "3                1           3.70           1                  N   \n",
       "5                6           2.30           1                  N   \n",
       "\n",
       "   PULocationID  DOLocationID  payment_type  fare_amount  extra  mta_tax  \\\n",
       "0           100           231             1         13.0    0.0      0.5   \n",
       "1           186            43             1         16.0    0.0      0.5   \n",
       "2           262           236             1          6.5    0.0      0.5   \n",
       "3           188            97             1         20.5    0.0      0.5   \n",
       "5           161           236             1          9.0    0.5      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0        2.76           0.0                    0.3         16.56   \n",
       "1        4.00           0.0                    0.3         20.80   \n",
       "2        1.45           0.0                    0.3          8.75   \n",
       "3        6.39           0.0                    0.3         27.69   \n",
       "5        2.06           0.0                    0.3         12.36   \n",
       "\n",
       "   mean_duration  mean_distance  predicted_fare  tip_percent  generous  \\\n",
       "0      22.847222       3.521667       16.434245        0.200         1   \n",
       "1      24.470370       3.108889       16.052218        0.238         1   \n",
       "2       7.250000       0.881429        7.053706        0.199         0   \n",
       "3      30.250000       3.700000       18.731650        0.300         1   \n",
       "5      11.855376       2.052258       10.441351        0.200         1   \n",
       "\n",
       "        day  am_rush  daytime  pm_rush  nighttime month  \n",
       "0  saturday        1        0        0          0   mar  \n",
       "1   tuesday        0        1        0          0   apr  \n",
       "2    friday        1        0        0          0   dec  \n",
       "3    sunday        0        1        0          0   may  \n",
       "5  saturday        0        0        0          1   mar  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns\n",
    "\n",
    "Drop redundant and irrelevant columns as well as those that would not be available when the model is deployed. This includes information like payment type, trip distance, tip amount, tip percentage, total amount, toll amount, etc. The target variable (`generous`) must remain in the data because it will get isolated as the `y` data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_distance</th>\n",
       "      <th>predicted_fare</th>\n",
       "      <th>generous</th>\n",
       "      <th>day</th>\n",
       "      <th>am_rush</th>\n",
       "      <th>daytime</th>\n",
       "      <th>pm_rush</th>\n",
       "      <th>nighttime</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>22.847222</td>\n",
       "      <td>3.521667</td>\n",
       "      <td>16.434245</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>43</td>\n",
       "      <td>24.470370</td>\n",
       "      <td>3.108889</td>\n",
       "      <td>16.052218</td>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>apr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>262</td>\n",
       "      <td>236</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>7.053706</td>\n",
       "      <td>0</td>\n",
       "      <td>friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>97</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>18.731650</td>\n",
       "      <td>1</td>\n",
       "      <td>sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>236</td>\n",
       "      <td>11.855376</td>\n",
       "      <td>2.052258</td>\n",
       "      <td>10.441351</td>\n",
       "      <td>1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID  passenger_count  RatecodeID  PULocationID  DOLocationID  \\\n",
       "0         2                6           1           100           231   \n",
       "1         1                1           1           186            43   \n",
       "2         1                1           1           262           236   \n",
       "3         2                1           1           188            97   \n",
       "5         2                6           1           161           236   \n",
       "\n",
       "   mean_duration  mean_distance  predicted_fare  generous       day  am_rush  \\\n",
       "0      22.847222       3.521667       16.434245         1  saturday        1   \n",
       "1      24.470370       3.108889       16.052218         1   tuesday        0   \n",
       "2       7.250000       0.881429        7.053706         0    friday        1   \n",
       "3      30.250000       3.700000       18.731650         1    sunday        0   \n",
       "5      11.855376       2.052258       10.441351         1  saturday        0   \n",
       "\n",
       "   daytime  pm_rush  nighttime month  \n",
       "0        0        0          0   mar  \n",
       "1        1        0          0   apr  \n",
       "2        0        0          0   dec  \n",
       "3        1        0          0   may  \n",
       "5        0        0          1   mar  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns\n",
    "df = df1.drop(\n",
    "    [\n",
    "        'Unnamed: 0', \n",
    "        'tpep_pickup_datetime', \n",
    "        'tpep_dropoff_datetime',\n",
    "        'payment_type', \n",
    "        'trip_distance', \n",
    "        'tip_amount', \n",
    "        'tip_percent', \n",
    "        'total_amount', \n",
    "        'store_and_fwd_flag', \n",
    "        'extra', \n",
    "        'mta_tax', \n",
    "        'tolls_amount', \n",
    "        'improvement_surcharge',\n",
    "        'fare_amount'\n",
    "    ], axis=1\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15265 entries, 0 to 22698\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   VendorID         15265 non-null  int64  \n",
      " 1   passenger_count  15265 non-null  int64  \n",
      " 2   RatecodeID       15265 non-null  int64  \n",
      " 3   PULocationID     15265 non-null  int64  \n",
      " 4   DOLocationID     15265 non-null  int64  \n",
      " 5   mean_duration    15265 non-null  float64\n",
      " 6   mean_distance    15265 non-null  float64\n",
      " 7   predicted_fare   15265 non-null  float64\n",
      " 8   generous         15265 non-null  int32  \n",
      " 9   day              15265 non-null  object \n",
      " 10  am_rush          15265 non-null  int32  \n",
      " 11  daytime          15265 non-null  int32  \n",
      " 12  pm_rush          15265 non-null  int32  \n",
      " 13  nighttime        15265 non-null  int32  \n",
      " 14  month            15265 non-null  object \n",
      "dtypes: float64(3), int32(5), int64(5), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVs01W-Iitu7"
   },
   "source": [
    "Many of the columns are categorical and will need to be dummied (converted to binary). Some of these columns are numeric, but they actually encode categorical information, such as `RatecodeID` and the pickup and dropoff locations. To make these columns recognizable to the `get_dummies()` function as categorical variables, you'll first need to convert them to `type(str)`. \n",
    "\n",
    "1. Define a variable called `cols_to_str`, which is a list of the numeric columns that contain categorical information and must be converted to string: `RatecodeID`, `PULocationID`, `DOLocationID`.\n",
    "2. Write a for loop that converts each column in `cols_to_str` to string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FbB4AfATHqjC"
   },
   "outputs": [],
   "source": [
    "# 1. Define list of cols to convert to string\n",
    "cols_to_str = ['RatecodeID', 'PULocationID', 'DOLocationID', 'VendorID']\n",
    "\n",
    "# 2. Convert each column to string\n",
    "for col in cols_to_str:\n",
    "    df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID          2\n",
       "RatecodeID        6\n",
       "PULocationID    124\n",
       "DOLocationID    193\n",
       "day               7\n",
       "month            12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=['object']).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j6Nyb5RnsvC"
   },
   "source": [
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To convert to string, use `astype(str)` on the column.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5Ubw8O1pKRO"
   },
   "source": [
    "Now convert all the categorical columns to binary.\n",
    "\n",
    "1. Call `get_dummies()` on the dataframe and assign the results back to a new dataframe called `df2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "H94yLzUMHqgB"
   },
   "outputs": [],
   "source": [
    "# Convert categoricals to binary\n",
    "df2 = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15265 entries, 0 to 22698\n",
      "Columns: 347 entries, passenger_count to month_sep\n",
      "dtypes: float64(3), int32(5), int64(1), uint8(338)\n",
      "memory usage: 5.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (15265, 347))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.info(), df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZfNE37b-LlJ"
   },
   "source": [
    "##### Evaluation metric\n",
    "\n",
    "Before modeling, you must decide on an evaluation metric. \n",
    "\n",
    "1. Examine the class balance of your target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4mRefXCF-K_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.526368\n",
       "0    0.473632\n",
       "Name: generous, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class balance of 'generous' col\n",
    "df2['generous'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjgkLrOf_OrE"
   },
   "source": [
    "Approximately nearlyt 53% of the customers in this dataset were \"generous\" (tipped ≥ 20%). The dataset is not imbalanced.\n",
    "\n",
    "To determine a metric, consider the cost of both kinds of model error:\n",
    "* False positives (the model predicts a tip ≥ 20%, but the customer does not give one)\n",
    "* False negatives (the model predicts a tip < 20%, but the customer gives more)\n",
    "\n",
    "**False positives are worse for cab drivers,** because they would pick up a customer expecting a good tip and then not receive one, frustrating the driver.\n",
    "\n",
    "**False negatives are worse for customers,** because a cab driver would likely pick up a different customer who was predicted to tip more&mdash;even when the original customer would have tipped generously.\n",
    "\n",
    "**The stakes are relatively even. You want to help taxi drivers make more money, but you don't want this to anger customers. Your metric should weigh both precision and recall equally. Which metric is this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "The metric that weighs both precision and recall equally is the **F1 score**. The F1 score is the harmonic mean of precision and recall, providing a balanced assessment of a model's performance in terms of both false positives and false negatives. It considers both types of errors and is particularly useful when the stakes are relatively even, as it aims to find a balance between correctly identifying positive cases and minimizing false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n1eikFh8akS"
   },
   "source": [
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Construct**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Construct stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5jzGjOS8iiv"
   },
   "source": [
    "### **Task 3. Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx41bVxX89Fe"
   },
   "source": [
    "##### **Split the data**\n",
    "\n",
    "Now you're ready to model. The only remaining step is to split the data into features/target variable and training/testing data. \n",
    "\n",
    "1. Define a variable `y` that isolates the target variable (`generous`).\n",
    "2. Define a variable `X` that isolates the features.\n",
    "3. Split the data into training and testing sets. Put 20% of the samples into the test set, stratify the data, and set the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qLbapbSWDUL-"
   },
   "outputs": [],
   "source": [
    "# Isolate target variable (y)\n",
    "y = df2['generous'].copy()\n",
    "\n",
    "# Isolate the features (X)\n",
    "X = df2.drop('generous', axis=1).copy()\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vynZs5het1b_"
   },
   "source": [
    "##### **Random forest**\n",
    "\n",
    "Begin with using `GridSearchCV` to tune a random forest model.\n",
    "\n",
    "1. Instantiate the random forest classifier `rf` and set the random state.\n",
    "\n",
    "2. Create a dictionary `cv_params` of any of the following hyperparameters and their corresponding values to tune. The more you tune, the better your model will fit the data, but the longer it will take. \n",
    " - `max_depth`  \n",
    " - `max_features`  \n",
    " - `max_samples` \n",
    " - `min_samples_leaf`  \n",
    " - `min_samples_split`\n",
    " - `n_estimators`  \n",
    "\n",
    "3. Define a dictionary `scoring` of scoring metrics for GridSearch to capture (precision, recall, F1 score, and accuracy).\n",
    "\n",
    "4. Instantiate the `GridSearchCV` object `rf1`. Pass to it as arguments:\n",
    " - estimator=`rf`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of you cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit=_`)\n",
    "\n",
    "\n",
    "**Note:** `refit` should be set to `'f1'`.<font/>\n",
    "</details>\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "params = {\n",
    "    'max_depth': [None, 5, 10],              # Maximum depth of the individual trees\n",
    "    'max_features': ['auto', 'sqrt', 0.5],   # Maximum number of features considered for splitting a node\n",
    "    'max_samples': [None, 0.5, 0.9],         # Maximum number of samples used for fitting each tree\n",
    "    'min_samples_leaf': [1, 2, 4],           # Minimum number of samples required to be at a leaf node\n",
    "    'min_samples_split': [2, 5, 10],         # Minimum number of samples required to split an internal node\n",
    "    'n_estimators': [50, 100, 200]           # Number of trees in the forest\n",
    "}\n",
    "\n",
    "# 3. Define a list of scoring metrics to capture\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "rf_cv = GridSearchCV(rf, \n",
    "                     param_grid=params, \n",
    "                     scoring=scoring, \n",
    "                     cv=5, \n",
    "                     n_jobs=-1, \n",
    "                     refit='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv_WvRA1RqTl"
   },
   "source": [
    "Now fit the model to the training data. Note that, depending on how many options you include in your search grid and the number of cross-validation folds you select, this could take a very long time&mdash;even hours. If you use 4-fold validation and include only one possible value for each hyperparameter and grow 300 trees to full depth, it should take about 5 minutes. If you add another value for GridSearch to check for, say, `min_samples_split` (so all hyperparameters now have 1 value except for `min_samples_split`, which has 2 possibilities), it would double the time to ~10 minutes. Each additional parameter would approximately double the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "OXuBiTGi5ZHn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1215 fits failed out of a total of 3645.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "466 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "749 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68719489 0.69112589 0.69374542\n",
      " 0.69390949 0.69620246 0.69685752 0.70275332 0.70267099 0.70267139\n",
      " 0.70709353 0.70938599 0.70987726 0.70791236 0.71028693 0.70987719\n",
      " 0.70971369 0.71028689 0.71020489 0.71126949 0.71274322 0.71249742\n",
      " 0.71126949 0.71274322 0.71249742 0.71151502 0.71323449 0.71257922\n",
      " 0.69505582 0.70201632 0.70414532 0.70250793 0.70545596 0.70692966\n",
      " 0.70570082 0.70815766 0.70881276 0.71126926 0.71364396 0.71315252\n",
      " 0.70938592 0.71176046 0.71290682 0.70905842 0.71266132 0.71249742\n",
      " 0.71200612 0.71298872 0.71307059 0.71200612 0.71298872 0.71307059\n",
      " 0.71249759 0.71331636 0.71257926 0.68604822 0.68965149 0.69251726\n",
      " 0.69841306 0.69939576 0.70095166 0.69923233 0.70242589 0.70316272\n",
      " 0.70684783 0.71069606 0.71053229 0.70971376 0.71045059 0.71085992\n",
      " 0.70995939 0.71176062 0.71085986 0.71339822 0.71372576 0.71266122\n",
      " 0.71339822 0.71372576 0.71266122 0.71266132 0.71347999 0.71266119\n",
      " 0.67499345 0.67761442 0.67990726 0.68023439 0.68154405 0.68383705\n",
      " 0.68613073 0.68989736 0.69014276 0.68580289 0.68784966 0.68711266\n",
      " 0.68686682 0.68711225 0.68809536 0.69055145 0.69309019 0.69423676\n",
      " 0.69636596 0.69775775 0.69800346 0.69636596 0.69775775 0.69800346\n",
      " 0.69693969 0.69955969 0.69947786 0.68940599 0.69489192 0.69718492\n",
      " 0.69440076 0.69931342 0.69849509 0.70111573 0.70291712 0.70357222\n",
      " 0.69824916 0.70086979 0.70193446 0.69824966 0.70127939 0.70201639\n",
      " 0.70308109 0.70381803 0.70488236 0.70332689 0.70529226 0.70643843\n",
      " 0.70332689 0.70529226 0.70643843 0.70463723 0.70521013 0.70733892\n",
      " 0.67532122 0.67835159 0.67966112 0.68260956 0.68645759 0.68678529\n",
      " 0.68678502 0.68907775 0.69137062 0.68596636 0.68629382 0.69079749\n",
      " 0.68760369 0.69055142 0.69104305 0.69333649 0.69661162 0.69571069\n",
      " 0.69915019 0.69808572 0.69824936 0.69915019 0.69808572 0.69824936\n",
      " 0.69939589 0.69898659 0.69988749        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.71249739 0.71282489 0.71274299 0.71216989 0.71290676 0.71282486\n",
      " 0.71176046 0.71298869 0.71307052 0.71249746 0.71274309 0.71241549\n",
      " 0.71266116 0.71274306 0.71241546 0.71200619 0.71274296 0.71282486\n",
      " 0.71143302 0.71216989 0.71274296 0.71143302 0.71216989 0.71274296\n",
      " 0.71167872 0.71233359 0.71241546 0.70954922 0.71233356 0.71282486\n",
      " 0.70897595 0.71184219 0.71307052 0.70954922 0.71233356 0.71315239\n",
      " 0.70897599 0.71266102 0.71315249 0.70922172 0.71233342 0.71290686\n",
      " 0.70938535 0.71266106 0.71307066 0.70963095 0.71225166 0.71323429\n",
      " 0.70963095 0.71225166 0.71323429 0.71004049 0.71241542 0.71315249\n",
      " 0.71167846 0.71282479 0.71298859 0.71208796 0.71290669 0.71282479\n",
      " 0.71176046 0.71257926 0.71282482 0.71184232 0.71282482 0.71257919\n",
      " 0.71200612 0.71290672 0.71274296 0.71216992 0.71274299 0.71266106\n",
      " 0.71143282 0.71266109 0.71249739 0.71143282 0.71266109 0.71249739\n",
      " 0.71151476 0.71274299 0.71249736 0.71388946 0.71397142 0.71372572\n",
      " 0.71372566 0.71397139 0.71397142 0.71364379 0.71413512 0.71380762\n",
      " 0.71380756 0.71388949 0.71364386 0.71388942 0.71380759 0.71397136\n",
      " 0.71356189 0.71405319 0.71388949 0.71397132 0.71397136 0.71388952\n",
      " 0.71397132 0.71397136 0.71388952 0.71380749 0.71405322 0.71372572\n",
      " 0.71356196 0.71372572 0.71380756 0.71372572 0.71356196 0.71380756\n",
      " 0.71356199 0.71364382 0.71364382 0.71356196 0.71380762 0.71380759\n",
      " 0.71364382 0.71380762 0.71380759 0.71348006 0.71364386 0.71388949\n",
      " 0.71405326 0.71372572 0.71372572 0.71405326 0.71372572 0.71372572\n",
      " 0.71380759 0.71356199 0.71372576 0.71372576 0.71388942 0.71388946\n",
      " 0.71372579 0.71397129 0.71372566 0.71356199 0.71388942 0.71364376\n",
      " 0.71356206 0.71380756 0.71364372 0.71356202 0.71397132 0.71372562\n",
      " 0.71364386 0.71380756 0.71356186 0.71339819 0.71380752 0.71339812\n",
      " 0.71339819 0.71380752 0.71339812 0.71331632 0.71372566 0.71339812\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.71307039 0.71298862 0.71315236\n",
      " 0.71274296 0.71307059 0.71274299 0.71266112 0.71307059 0.71339809\n",
      " 0.71315246 0.71282482 0.71323422 0.71266116 0.71307049 0.71298866\n",
      " 0.71241549 0.71315249 0.71307056 0.71225176 0.71274309 0.71315246\n",
      " 0.71225176 0.71274309 0.71315246 0.71298869 0.71331622 0.71315239\n",
      " 0.71184222 0.71307059 0.71364379 0.71249742 0.71323449 0.71348006\n",
      " 0.71257922 0.71282482 0.71356186 0.71257926 0.71339816 0.71307059\n",
      " 0.71282492 0.71339816 0.71339812 0.71249729 0.71323439 0.71298869\n",
      " 0.71225159 0.71331616 0.71331626 0.71225159 0.71331616 0.71331626\n",
      " 0.71249732 0.71298869 0.71356196 0.71282496 0.71298859 0.71339806\n",
      " 0.71257922 0.71323426 0.71339806 0.71307076 0.71356186 0.71347989\n",
      " 0.71307056 0.71380742 0.71347996 0.71192426 0.71380749 0.71348006\n",
      " 0.71225182 0.71339802 0.71339809 0.71266116 0.71282496 0.71307062\n",
      " 0.71266116 0.71282496 0.71307062 0.71249752 0.71282486 0.71290682\n",
      " 0.71143265 0.71176042 0.71233356 0.71036836 0.71159656 0.71241539\n",
      " 0.71176042 0.71241549 0.71282496 0.71184232 0.71192402 0.71233366\n",
      " 0.71192419 0.71208796 0.71225179 0.71249739 0.71225169 0.71249736\n",
      " 0.71151489 0.71216989 0.71233366 0.71151489 0.71216989 0.71233366\n",
      " 0.71159679 0.71249742 0.71208806 0.71184226 0.71282496 0.71274312\n",
      " 0.71135099 0.71257922 0.71298869 0.71266139 0.71298876 0.71364379\n",
      " 0.71151482 0.71339802 0.71315246 0.71184226 0.71282486 0.71298866\n",
      " 0.71192412 0.71290676 0.71315239 0.71241556 0.71307056 0.71266119\n",
      " 0.71241556 0.71307056 0.71266119 0.71249736 0.71298876 0.71282506\n",
      " 0.71176039 0.71233366 0.71249739 0.71200596 0.71208786 0.71274302\n",
      " 0.71200589 0.71225159 0.71225166 0.71208799 0.71216992 0.71216989\n",
      " 0.71208789 0.71200602 0.71225169 0.71135102 0.71249732 0.71257926\n",
      " 0.71200599 0.71249739 0.71249736 0.71200599 0.71249739 0.71249736\n",
      " 0.71143282 0.71176039 0.71233366]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68445737 0.68498349 0.68603104\n",
      " 0.685976   0.68682952 0.68647413 0.69073481 0.68998708 0.69009225\n",
      " 0.69142637 0.69296339 0.69365319 0.69250821 0.69391532 0.69330951\n",
      " 0.69369882 0.69372072 0.69327153 0.69298024 0.69446912 0.69421536\n",
      " 0.69298024 0.69446912 0.69421536 0.69406956 0.69533652 0.69471434\n",
      " 0.68824155 0.69079803 0.69114859 0.68924174 0.69116032 0.69162977\n",
      " 0.69094065 0.69209129 0.69256089 0.69414743 0.69572074 0.69546532\n",
      " 0.69289293 0.69442958 0.69523979 0.69201348 0.69515835 0.69467799\n",
      " 0.69394491 0.69471061 0.69506746 0.69394491 0.69471061 0.69506746\n",
      " 0.6946133  0.69519411 0.69446752 0.68418332 0.68447527 0.68510412\n",
      " 0.68880829 0.68873273 0.68950521 0.68832151 0.69014136 0.690124\n",
      " 0.69172479 0.69388782 0.69361195 0.69380092 0.69401354 0.6939706\n",
      " 0.69361159 0.69446149 0.69372881 0.69522787 0.69552768 0.69434329\n",
      " 0.69522787 0.69552768 0.69434329 0.6948924  0.69526033 0.69467222\n",
      " 0.67761119 0.67771058 0.67873133 0.67812323 0.67826955 0.67914429\n",
      " 0.68216438 0.68502683 0.68446293 0.6815368  0.68268063 0.68187422\n",
      " 0.6828969  0.68205075 0.68254996 0.68473295 0.68585786 0.68646971\n",
      " 0.68807813 0.68861962 0.68848933 0.68807813 0.68861962 0.68848933\n",
      " 0.68813097 0.6900684  0.68971461 0.68377201 0.68636274 0.6876642\n",
      " 0.68610149 0.68928303 0.68794085 0.68944297 0.69098044 0.69118703\n",
      " 0.68854554 0.68942211 0.68985499 0.68795029 0.69036336 0.68986463\n",
      " 0.69090746 0.69102953 0.69113962 0.69051101 0.69202698 0.69241608\n",
      " 0.69051101 0.69202698 0.69241608 0.69142795 0.69166668 0.69253887\n",
      " 0.67664667 0.6775092  0.6779028  0.6793011  0.68224264 0.68157644\n",
      " 0.68192619 0.68355241 0.68475825 0.68178306 0.68050408 0.68427021\n",
      " 0.68298819 0.68440858 0.68426071 0.68664261 0.68851933 0.68757288\n",
      " 0.68941865 0.68898484 0.68842042 0.68941865 0.68898484 0.68842042\n",
      " 0.68938641 0.68871395 0.68952005        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69363382 0.6940507  0.69409014 0.69316639 0.6940654  0.69417549\n",
      " 0.69297411 0.69430287 0.69440615 0.69362979 0.69393668 0.69386942\n",
      " 0.69386009 0.69393959 0.69398029 0.69329015 0.69417889 0.69439009\n",
      " 0.69266632 0.69323517 0.6941413  0.69266632 0.69323517 0.6941413\n",
      " 0.69290027 0.69356944 0.69392849 0.68918229 0.69304618 0.69407999\n",
      " 0.68866382 0.69266244 0.69419771 0.68950937 0.69310801 0.69428799\n",
      " 0.68901591 0.69330608 0.69448231 0.68925818 0.6930973  0.69421115\n",
      " 0.68943837 0.69345682 0.69429174 0.68944272 0.69310773 0.69436976\n",
      " 0.68944272 0.69310773 0.69436976 0.68982705 0.69324492 0.69443204\n",
      " 0.69308595 0.69422709 0.69448404 0.69328555 0.69427125 0.69440737\n",
      " 0.69297431 0.69406124 0.69439764 0.69291304 0.69427163 0.69416371\n",
      " 0.6930343  0.69421743 0.69429559 0.69326327 0.69413459 0.69419966\n",
      " 0.69272005 0.69404887 0.69402594 0.69272005 0.69404887 0.69402594\n",
      " 0.69276054 0.69418908 0.6940714  0.6961273  0.69606424 0.69579068\n",
      " 0.69594615 0.69611457 0.69607374 0.6960127  0.69625335 0.69584137\n",
      " 0.69618875 0.69602412 0.69570357 0.69623012 0.69593427 0.69596894\n",
      " 0.69596664 0.69610848 0.69587672 0.6961255  0.69602324 0.69588468\n",
      " 0.6961255  0.69602324 0.69588468 0.6959968  0.69606519 0.69580753\n",
      " 0.69591152 0.69583962 0.69584142 0.69599096 0.69570905 0.69584142\n",
      " 0.69601572 0.6957991  0.69575943 0.69595918 0.69587824 0.69588997\n",
      " 0.69600061 0.69592632 0.69593795 0.6959793  0.6957964  0.6959286\n",
      " 0.69630712 0.69594487 0.69589657 0.69630712 0.69594487 0.69589657\n",
      " 0.69613732 0.69581097 0.69589377 0.6962999  0.69593136 0.69593643\n",
      " 0.69619481 0.69602061 0.69580813 0.69611709 0.69593136 0.69576897\n",
      " 0.69616454 0.69588406 0.69565617 0.69610984 0.69602169 0.69575245\n",
      " 0.69620794 0.69589074 0.69567252 0.69604239 0.69588806 0.69554893\n",
      " 0.69604239 0.69588806 0.69554893 0.69595034 0.69590813 0.69554893\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.6949081  0.69481501 0.69500763\n",
      " 0.69468731 0.69494546 0.69459407 0.6946008  0.69495769 0.6952839\n",
      " 0.69488219 0.69462757 0.69499318 0.6945864  0.69494628 0.6949632\n",
      " 0.69437242 0.69493258 0.69485712 0.69413248 0.694476   0.69494932\n",
      " 0.69413248 0.694476   0.69494932 0.69460678 0.69491555 0.6948945\n",
      " 0.6935346  0.69493771 0.69554297 0.69402458 0.69487589 0.69552729\n",
      " 0.69415088 0.6944681  0.6955574  0.69423945 0.69527498 0.69512323\n",
      " 0.69451558 0.69516733 0.69544007 0.69438706 0.6948842  0.69491263\n",
      " 0.69378134 0.69526602 0.69528318 0.69378134 0.69526602 0.69528318\n",
      " 0.69412826 0.69471408 0.69539345 0.69483713 0.69483209 0.69532955\n",
      " 0.69432613 0.69514045 0.69544239 0.6950198  0.69551594 0.69543844\n",
      " 0.6950668  0.6957967  0.69539548 0.69417073 0.69560932 0.69532487\n",
      " 0.69421118 0.69522814 0.69518803 0.69431968 0.69474093 0.6951401\n",
      " 0.69431968 0.69474093 0.6951401  0.69437774 0.6949511  0.69510515\n",
      " 0.6948216  0.69489453 0.69521609 0.69412758 0.69478772 0.69518847\n",
      " 0.69486337 0.69540257 0.69533676 0.6949164  0.6949064  0.6949423\n",
      " 0.69506359 0.69524268 0.69495993 0.69558219 0.6953137  0.69522822\n",
      " 0.69460649 0.69507744 0.69509796 0.69460649 0.69507744 0.69509796\n",
      " 0.69469343 0.6953445  0.69498809 0.69562602 0.69561433 0.69536896\n",
      " 0.69497324 0.69544823 0.69537306 0.69571242 0.69564104 0.6960223\n",
      " 0.6950561  0.69590591 0.69562609 0.69500329 0.69541991 0.69553726\n",
      " 0.69488731 0.69550442 0.69558118 0.69580588 0.6958975  0.69548719\n",
      " 0.69580588 0.6958975  0.69548719 0.69585209 0.69570709 0.69551099\n",
      " 0.69512096 0.69531197 0.6952428  0.69528201 0.69513464 0.6954474\n",
      " 0.69498778 0.69532369 0.69511796 0.69516389 0.69532801 0.69511313\n",
      " 0.69527485 0.6948502  0.69505415 0.69444817 0.69525043 0.69527276\n",
      " 0.69506288 0.69530516 0.6951917  0.69506288 0.69530516 0.6951917\n",
      " 0.69477452 0.69479214 0.69495427]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.76031556 0.77236989 0.77839592\n",
      " 0.77901368 0.78442267 0.78782393 0.79508632 0.797095   0.79678683\n",
      " 0.80791285 0.81100368 0.81053988 0.80729437 0.81115764 0.81162144\n",
      " 0.80976768 0.81177624 0.81285828 0.81733943 0.81780287 0.81780287\n",
      " 0.81733943 0.81780287 0.81780287 0.81486671 0.81687539 0.81656615\n",
      " 0.77638725 0.79245917 0.79864083 0.79879623 0.80312306 0.80667685\n",
      " 0.80451397 0.80945833 0.81023077 0.81378563 0.81718451 0.81625727\n",
      " 0.8111586  0.81471239 0.81610259 0.81270396 0.81548507 0.81641207\n",
      " 0.81687563 0.81795707 0.81718463 0.81687563 0.81795707 0.81718463\n",
      " 0.81656651 0.81764795 0.81733883 0.75722425 0.76896982 0.77700596\n",
      " 0.78658662 0.78998657 0.79292261 0.79045109 0.79601451 0.79864095\n",
      " 0.80621293 0.81270276 0.81301224 0.80961312 0.8114676  0.81301272\n",
      " 0.81100404 0.81455724 0.81378492 0.81780287 0.81795731 0.81795755\n",
      " 0.81780287 0.81795731 0.81795755 0.81625775 0.81795719 0.81703007\n",
      " 0.73837026 0.74718027 0.7522799  0.75537205 0.75938845 0.76495151\n",
      " 0.76356191 0.76804318 0.7706701  0.76448986 0.7681975  0.76804294\n",
      " 0.7641786  0.76757879 0.76943338 0.77128762 0.77669613 0.77885984\n",
      " 0.78133351 0.78442362 0.78581406 0.78133351 0.78442362 0.78581406\n",
      " 0.7830333  0.78627846 0.78720522 0.77005234 0.78133315 0.7853505\n",
      " 0.78055999 0.78782322 0.78905969 0.79338652 0.794932   0.79663144\n",
      " 0.78627774 0.7926142  0.79493248 0.78828702 0.79137749 0.79539544\n",
      " 0.79570611 0.79786899 0.80126787 0.79771443 0.7998785  0.80265866\n",
      " 0.79771443 0.7998785  0.80265866 0.79941387 0.80080454 0.8054399\n",
      " 0.74223353 0.75042471 0.7539791  0.75985272 0.76448736 0.76773394\n",
      " 0.76665131 0.76974214 0.77422365 0.76417979 0.76943374 0.77360589\n",
      " 0.76618739 0.77221414 0.7743775  0.77499776 0.78071491 0.78071467\n",
      " 0.78689658 0.78457902 0.7867419  0.78689658 0.78457902 0.7867419\n",
      " 0.78782393 0.78844193 0.78921461        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.81965699 0.81934799 0.81903899 0.8199661  0.8196571  0.81903899\n",
      " 0.81919331 0.81919355 0.81919331 0.81965699 0.81950266 0.81857531\n",
      " 0.81950231 0.81950266 0.81826607 0.81903887 0.81872987 0.81842063\n",
      " 0.81903887 0.8196571  0.81888443 0.81903887 0.8196571  0.81888443\n",
      " 0.81919343 0.81919355 0.81842075 0.82367613 0.82089334 0.81934811\n",
      " 0.82336689 0.82042966 0.81981166 0.82259421 0.82073878 0.81981166\n",
      " 0.82243953 0.82120234 0.81919355 0.82243977 0.82073866 0.81919355\n",
      " 0.82228509 0.82073878 0.81950266 0.82321209 0.8204299  0.81981143\n",
      " 0.82321209 0.8204299  0.81981143 0.82336665 0.82058434 0.81934811\n",
      " 0.81857531 0.81888431 0.81872975 0.81934787 0.81903887 0.81842075\n",
      " 0.81919343 0.81857519 0.81842075 0.81965687 0.81872987 0.81826643\n",
      " 0.81981143 0.81919343 0.81842099 0.81965699 0.81888431 0.81842099\n",
      " 0.81888419 0.81888431 0.81842099 0.81888419 0.81888431 0.81842099\n",
      " 0.81903887 0.81872987 0.81826643 0.81672095 0.81718451 0.81718451\n",
      " 0.81672095 0.81702995 0.81718451 0.81625727 0.81718439 0.81733895\n",
      " 0.81625727 0.81702995 0.81718439 0.81641183 0.81702995 0.81749351\n",
      " 0.81610283 0.81733895 0.81749351 0.81702995 0.81733895 0.81749351\n",
      " 0.81702995 0.81733895 0.81749351 0.81687539 0.81749363 0.81718439\n",
      " 0.81625763 0.81703007 0.81733907 0.81656663 0.81687563 0.81733907\n",
      " 0.81594875 0.81687575 0.81703007 0.81610295 0.81718463 0.81718451\n",
      " 0.81625751 0.81703007 0.81702995 0.81579407 0.81687575 0.81733907\n",
      " 0.81672095 0.81672095 0.81687539 0.81672095 0.81672095 0.81687539\n",
      " 0.81641195 0.81656651 0.81687539 0.81563903 0.81733883 0.81733895\n",
      " 0.81594815 0.81733883 0.81718439 0.81563903 0.81733883 0.81702983\n",
      " 0.81548471 0.81718427 0.81733895 0.81563927 0.81733883 0.81733895\n",
      " 0.81563915 0.81718439 0.81702983 0.81533027 0.81718451 0.81687527\n",
      " 0.81533027 0.81718451 0.81687527 0.81533039 0.81687539 0.81687527\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.81764819 0.81764807 0.81764795\n",
      " 0.81718451 0.81749351 0.81749363 0.81718439 0.81749363 0.81764807\n",
      " 0.81795731 0.81764819 0.81795707 0.81718475 0.81749363 0.81718451\n",
      " 0.81703007 0.81780275 0.81780251 0.81718475 0.81780263 0.81780263\n",
      " 0.81718475 0.81780263 0.81780263 0.81826643 0.81842087 0.81795719\n",
      " 0.81749387 0.81749387 0.81764819 0.81826679 0.81826667 0.81718451\n",
      " 0.81826655 0.81811187 0.81733907 0.81795755 0.81764843 0.81702983\n",
      " 0.81795731 0.81795731 0.81718439 0.81718463 0.81826655 0.81733907\n",
      " 0.81811199 0.81733931 0.81733895 0.81811199 0.81733931 0.81733895\n",
      " 0.81795755 0.81795731 0.81780263 0.81703031 0.81764831 0.81749351\n",
      " 0.81780275 0.81749351 0.81718451 0.81733955 0.81749399 0.81749351\n",
      " 0.81718439 0.81749363 0.81764807 0.81594851 0.81795719 0.81780263\n",
      " 0.81702995 0.81780275 0.81795731 0.81811187 0.81733907 0.81702983\n",
      " 0.81811187 0.81733907 0.81702983 0.81733919 0.81672071 0.81656627\n",
      " 0.81239388 0.81332136 0.81424848 0.81084876 0.813012   0.81455748\n",
      " 0.81332172 0.81393936 0.81548483 0.81347592 0.81378468 0.81502115\n",
      " 0.81332136 0.81332124 0.81471216 0.81363048 0.81363012 0.81471192\n",
      " 0.81332184 0.81409404 0.8145576  0.81332184 0.81409404 0.8145576\n",
      " 0.81332196 0.81440316 0.81409416 0.8113128  0.81471227 0.81517571\n",
      " 0.81162144 0.81440292 0.81594827 0.81378575 0.81517595 0.81625703\n",
      " 0.81193092 0.81579371 0.81579359 0.81316692 0.81532992 0.81548436\n",
      " 0.81378528 0.81533015 0.81594792 0.8127036  0.81471227 0.81455736\n",
      " 0.8127036  0.81471227 0.81455736 0.81285792 0.81502115 0.81502092\n",
      " 0.81254904 0.81393948 0.81471192 0.81285768 0.81363024 0.81486648\n",
      " 0.81378504 0.81363012 0.81424836 0.81347592 0.813321   0.81393912\n",
      " 0.8131668  0.81424824 0.81440244 0.81316728 0.81471192 0.81486636\n",
      " 0.81363036 0.81455748 0.8148666  0.81363036 0.81455748 0.8148666\n",
      " 0.81254868 0.81363036 0.81502115]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.7203412  0.7260082  0.72925315\n",
      " 0.72948967 0.7323377  0.73363936 0.73921459 0.73963997 0.73956936\n",
      " 0.74509257 0.74729543 0.74750677 0.7454474  0.74791647 0.74776761\n",
      " 0.74720937 0.74807583 0.74827257 0.7499965  0.75105568 0.75090937\n",
      " 0.7499965  0.75105568 0.75090937 0.74957356 0.75116821 0.75067041\n",
      " 0.72959258 0.7380948  0.74097326 0.73989669 0.74288814 0.74469148\n",
      " 0.74337792 0.7461442  0.74675334 0.74918324 0.7515171  0.75098464\n",
      " 0.74732563 0.74973007 0.75078464 0.74747925 0.75048027 0.75058975\n",
      " 0.75036243 0.75125925 0.75114038 0.75036243 0.75125925 0.75114038\n",
      " 0.75061717 0.75140695 0.75085092 0.71878969 0.72421228 0.72811954\n",
      " 0.73434525 0.73581766 0.73753512 0.7358003  0.7392459  0.74035535\n",
      " 0.74454693 0.74856592 0.74852411 0.74718784 0.74810705 0.74873682\n",
      " 0.74767441 0.74967002 0.74892373 0.7515003  0.75173974 0.75105006\n",
      " 0.7515003  0.75173974 0.75105006 0.75065495 0.75158113 0.75083691\n",
      " 0.70649127 0.71062705 0.71348432 0.714526   0.71641197 0.719371\n",
      " 0.72046995 0.72407004 0.72491887 0.72052019 0.72282633 0.72231973\n",
      " 0.72116436 0.72219671 0.72329365 0.72536328 0.7283741  0.72966354\n",
      " 0.73166172 0.73333853 0.73386164 0.73166172 0.73333853 0.73386164\n",
      " 0.73246975 0.73498163 0.73516564 0.72428701 0.73070244 0.73319465\n",
      " 0.7302062  0.73520258 0.73497064 0.7377021  0.73926311 0.74011045\n",
      " 0.73410776 0.73736639 0.73862536 0.73462385 0.73734018 0.73880233\n",
      " 0.73956398 0.74056508 0.74208511 0.74019438 0.74201816 0.74342306\n",
      " 0.74019438 0.74201816 0.74342306 0.74144131 0.74217825 0.74467255\n",
      " 0.70777149 0.71197456 0.71379366 0.7172489  0.72095033 0.7219816\n",
      " 0.72172855 0.72401469 0.72663909 0.72053367 0.72213566 0.72610379\n",
      " 0.72211234 0.7255883  0.72642854 0.72804249 0.73164382 0.73107853\n",
      " 0.73487127 0.73362042 0.73424207 0.73487127 0.73362042 0.73424207\n",
      " 0.73526166 0.73515686 0.73592654        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.75134369 0.75145767 0.75134934 0.75120261 0.75158981 0.75140029\n",
      " 0.75075835 0.75153663 0.75159835 0.75134485 0.75145097 0.75103126\n",
      " 0.75141349 0.75145218 0.75095922 0.75088377 0.75127159 0.75125971\n",
      " 0.75051384 0.75111292 0.75131667 0.75051384 0.75111292 0.75131667\n",
      " 0.75071601 0.75111523 0.75099487 0.75030841 0.75150131 0.75147591\n",
      " 0.7498754  0.75107917 0.75174181 0.75006963 0.75147412 0.75179698\n",
      " 0.74967859 0.75178679 0.75165302 0.74983062 0.75147152 0.75149248\n",
      " 0.74989905 0.75168531 0.75166952 0.7502656  0.75134108 0.75184244\n",
      " 0.7502656  0.75134108 0.75184244 0.75056872 0.75148461 0.7516869\n",
      " 0.7505625  0.75135962 0.75144777 0.75100752 0.75145068 0.75127056\n",
      " 0.75075848 0.75113122 0.75126752 0.75091547 0.75132376 0.75107152\n",
      " 0.75105605 0.75148857 0.75121272 0.75112694 0.7513082  0.7511573\n",
      " 0.75047486 0.75125798 0.7510532  0.75047486 0.75125798 0.7510532\n",
      " 0.75056598 0.75127586 0.75101697 0.75156466 0.75172447 0.75156348\n",
      " 0.75146332 0.75168997 0.75172642 0.7513034  0.75183339 0.7516557\n",
      " 0.75140829 0.75163688 0.75151044 0.75149862 0.75158349 0.75179711\n",
      " 0.75121488 0.7518153  0.75174404 0.75169583 0.75176446 0.75174607\n",
      " 0.75169583 0.75176446 0.75174607 0.75155262 0.75185627 0.75156769\n",
      " 0.75124409 0.75152905 0.7516575  0.75142197 0.75138704 0.7516575\n",
      " 0.75117397 0.7514412  0.75147886 0.75120481 0.75161818 0.7516208\n",
      " 0.7512952  0.75158062 0.75158328 0.75108438 0.75144016 0.75171\n",
      " 0.75167148 0.75145918 0.75149304 0.75167148 0.75145918 0.75149304\n",
      " 0.75144215 0.75131635 0.75149194 0.75120128 0.75170953 0.75170986\n",
      " 0.751273   0.75176221 0.75156727 0.75109651 0.75170953 0.75148009\n",
      " 0.75105813 0.75161742 0.75154967 0.75109392 0.75176257 0.75160456\n",
      " 0.75114922 0.75162112 0.75142517 0.75092268 0.75162172 0.75128509\n",
      " 0.75092268 0.75162172 0.75128509 0.75086975 0.7514985  0.75128509\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.75124692 0.75118409 0.75129482\n",
      " 0.75092575 0.75120149 0.75099284 0.75086817 0.7512058  0.75145859\n",
      " 0.75136572 0.75108213 0.75142008 0.75086572 0.75120491 0.75107725\n",
      " 0.75067636 0.75132818 0.75128004 0.75060386 0.75105761 0.75133237\n",
      " 0.75060386 0.75105761 0.75133237 0.75133088 0.75157711 0.75136701\n",
      " 0.75039005 0.75120577 0.75162175 0.75099313 0.75148866 0.75140923\n",
      " 0.75105858 0.75118816 0.75149727 0.75098946 0.75146286 0.7511046\n",
      " 0.75114655 0.75152681 0.75135479 0.75074945 0.75149321 0.7511218\n",
      " 0.75079818 0.7513311  0.75133575 0.75079818 0.7513311  0.75133575\n",
      " 0.75092661 0.75126261 0.75160044 0.75095056 0.75119579 0.75142351\n",
      " 0.75095894 0.75130733 0.75135484 0.7511762  0.75152904 0.75148211\n",
      " 0.75113942 0.75169263 0.75151781 0.75009877 0.75178814 0.75154882\n",
      " 0.75057373 0.75149608 0.75153525 0.75109207 0.75101067 0.75111025\n",
      " 0.75109207 0.75101067 0.75111025 0.75080883 0.75087488 0.75089527\n",
      " 0.74896233 0.74940037 0.7499831  0.7479053  0.74921091 0.75010048\n",
      " 0.7493889  0.74996312 0.750579   0.74947764 0.74960373 0.75015096\n",
      " 0.74949919 0.74960259 0.75003279 0.74993742 0.74977608 0.75018857\n",
      " 0.74923817 0.7498395  0.75004732 0.74923817 0.7498395  0.75004732\n",
      " 0.7492891  0.75012088 0.7497799  0.74897456 0.75040893 0.75046433\n",
      " 0.74872152 0.75017524 0.75079779 0.75008444 0.75062694 0.75130314\n",
      " 0.74890043 0.75103441 0.75087041 0.74940395 0.75055208 0.75068943\n",
      " 0.7496067  0.75060997 0.75091121 0.74967203 0.75057446 0.75026841\n",
      " 0.74967203 0.75057446 0.75026841 0.74976525 0.75059281 0.75048093\n",
      " 0.74920798 0.74990865 0.75018806 0.74944238 0.74967346 0.75038563\n",
      " 0.74966057 0.74977953 0.74992135 0.74962652 0.74964897 0.74979362\n",
      " 0.74955804 0.74976448 0.74994819 0.74908358 0.75019417 0.75027708\n",
      " 0.74962661 0.75015986 0.75022782 0.74962661 0.75015986 0.75022782\n",
      " 0.74899934 0.74946276 0.75015674]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25.1 s\n",
      "Wall time: 37min 23s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, 0.5],\n",
       "                         &#x27;max_samples&#x27;: [None, 0.5, 0.9],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, 0.5],\n",
       "                         &#x27;max_samples&#x27;: [None, 0.5, 0.9],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 10],\n",
       "                         'max_features': ['auto', 'sqrt', 0.5],\n",
       "                         'max_samples': [None, 0.5, 0.9],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             refit='f1', scoring=['accuracy', 'precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHi_YJduQOH"
   },
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "If you get a warning that a metric is 0 due to no predicted samples, think about how many features you're sampling with `max_features`. How many features are in the dataset? How many are likely predictive enough to give good predictions within the number of splits you've allowed (determined by the `max_depth` hyperparameter)? Consider increasing `max_features`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChZsXw2sksDF"
   },
   "source": [
    "If you want, use `pickle` to save your models and read them back in. This can be particularly helpful when performing a search over many possible hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "YtAgrH0zy4CE"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Define a path to the folder where you want to save the model\n",
    "path = 'D:/1 DA Courses/2 Google Advanced Data Analytics - Coursera/Course 6 The Nuts and Bolts of Machine Learning/Week 5 Assessment/Automatidata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'best_rf_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle(path, model_object, save_name:str):\n",
    "    '''\n",
    "    save_name is a string.\n",
    "    '''\n",
    "    with open(path + save_name + '.pickle', 'wb') as to_write:\n",
    "        pickle.dump(model_object, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(path, saved_model_name:str):\n",
    "    '''\n",
    "    saved_model_name is a string.\n",
    "    '''\n",
    "    with open(path + saved_model_name + '.pickle', 'rb') as to_read:\n",
    "        model = pickle.load(to_read)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(path, rf_cv, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained GridSearchCV object\n",
    "loaded_rf_cv = read_pickle(path, model_name)\n",
    "\n",
    "# Now you can use the loaded_rf_cv object just like any other GridSearchCV object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIaRiZW4hf-6"
   },
   "source": [
    "Examine the best average score across all the validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "29kGUegqhviL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518562706844787"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heGb51fHh3E5"
   },
   "source": [
    "Examine the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "FjgXbO7Kh8is"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 0.5,\n",
       " 'max_samples': None,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZZnem5yiAau"
   },
   "source": [
    "Use the `make_results()` function to output all of the scores of your model. Note that it accepts three arguments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeW48TS742jN"
   },
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "To learn more about how this function accesses the cross-validation results, refer to the [`GridSearchCV` scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV) for the `cv_results_` attribute.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "u-UodWEOedxz"
   },
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "    model_name (string): what you want the model to be called in the output table\n",
    "    model_object: a fit GridSearchCV object\n",
    "    metric (string): precision, recall, f1, or accuracy\n",
    "\n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "\n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy],\n",
    "                        },\n",
    "                       )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI84Xo37ZLy0"
   },
   "source": [
    "Call `make_results()` on the GridSearch object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "qAYb2QigiT_h"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Random Forest CV</td>\n",
       "      <td>0.696253</td>\n",
       "      <td>0.817184</td>\n",
       "      <td>0.751833</td>\n",
       "      <td>0.714135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  precision    recall        F1  accuracy\n",
       "0  Tuned Random Forest CV   0.696253  0.817184  0.751833  0.714135"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = make_results('Tuned Random Forest CV', rf_cv, 'accuracy')\n",
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB-yhW9uu7dO"
   },
   "source": [
    "A model with such low F1, precision, and recall scores is not good enough. Optional: try to improve the scores. Generally, unless your hyperparameter search space is completely off the mark, you won't get the degree of improvement you need to approve this model. However, it's worth trying, especially to practice searching over different hyperparameters.\n",
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "\n",
    "For example, if the available values for `min_samples_split` were [2, 3, 4] and GridSearch identified the best value as 4, consider trying [4, 5, 6] this time.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your model to predict on the test data. Assign the results to a variable called `preds`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "    \n",
    "You cannot call `predict()` on the GridSearchCV object directly. You must call it on the `best_estimator_`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, you will use several models to predict on the test data. Remember that this decision comes with a trade-off. What is the benefit of this? What is the drawback?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycwjBHJjiT9J"
   },
   "source": [
    "Answer:\n",
    "\n",
    "The benefit of using multiple models to predict on the test data is that you can compare models using data that was not used to train/tune hyperparameters. This reduces the risk of selecting a model based on how well it fit the training data.\n",
    "\n",
    "The drawback of using the final test data to select a model is that, by using the unseen data to make a decision about which model to use, you no longer have a truly unbiased idea of how your model would be expected to perform on new data. In this case, think of final model selection as another way of \"tuning\" your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "preds = rf_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below `get_test_scores()` function you will use to output the scores of the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_scores(model_name:str, preds, y_test_data):\n",
    "    '''\n",
    "    Generate a table of test scores.\n",
    "\n",
    "    In:\n",
    "    model_name (string): Your choice: how the model will be named in the output table\n",
    "    preds: numpy array of test predictions\n",
    "    y_test_data: numpy array of y_test data\n",
    "\n",
    "    Out:\n",
    "    table: a pandas df of precision, recall, f1, and accuracy scores for your model\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_test_data, preds)\n",
    "    precision = precision_score(y_test_data, preds)\n",
    "    recall = recall_score(y_test_data, preds)\n",
    "    f1 = f1_score(y_test_data, preds)\n",
    "\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                        'precision': [precision],\n",
    "                        'recall': [recall],\n",
    "                        'F1': [f1],\n",
    "                        'accuracy': [accuracy]\n",
    "                        })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDRAL7zQx21J"
   },
   "source": [
    "1. Use the `get_test_scores()` function to generate the scores on the test data. Assign the results to `rf_test_scores`.\n",
    "2. Call `rf_test_scores` to output the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RF test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Iil1LjabiT5x"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Random Forest CV</td>\n",
       "      <td>0.696253</td>\n",
       "      <td>0.817184</td>\n",
       "      <td>0.751833</td>\n",
       "      <td>0.714135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Random Forest CV (Test)</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.806266</td>\n",
       "      <td>0.733993</td>\n",
       "      <td>0.700622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  precision    recall        F1  accuracy\n",
       "0         Tuned Random Forest CV   0.696253  0.817184  0.751833  0.714135\n",
       "0  Tuned Random Forest CV (Test)   0.673611  0.806266  0.733993  0.700622"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Get scores on test data\n",
    "result2 = get_test_scores('Tuned Random Forest CV (Test)', preds, y_test)\n",
    "result = pd.concat([result1, result2], axis=0)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4JiP5VRz2un"
   },
   "source": [
    "**Question:** How do your test results compare to your validation results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE6oXEJJiT2R"
   },
   "source": [
    "The test results are slightly lower than the validation results for all metrics (precision, recall, F1, and accuracy). This is a common observation and can be attributed to the fact that the model was tuned and optimized based on the validation set. As a result, the model might have slightly overfit to the validation set during the tuning process, leading to better performance on the validation set compared to the unseen test set.\n",
    "\n",
    "Even though the test scores are slightly lower, the overall performance of the model on the test set is still good compared to the training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **XGBoost**\n",
    "\n",
    " Try to improve your scores using an XGBoost model.\n",
    "\n",
    "1. Instantiate the XGBoost classifier `xgb` and set `objective='binary:logistic'`. Also set the random state.\n",
    "\n",
    "2. Create a dictionary `cv_params` of the following hyperparameters and their corresponding values to tune:\n",
    " - `max_depth`\n",
    " - `min_child_weight`\n",
    " - `learning_rate`\n",
    " - `n_estimators`\n",
    "\n",
    "3. Define a dictionary `scoring` of scoring metrics for grid search to capture (precision, recall, F1 score, and accuracy).\n",
    "\n",
    "4. Instantiate the `GridSearchCV` object `xgb1`. Pass to it as arguments:\n",
    " - estimator=`xgb`\n",
    " - param_grid=`cv_params`\n",
    " - scoring=`scoring`\n",
    " - cv: define the number of cross-validation folds you want (`cv=_`)\n",
    " - refit: indicate which evaluation metric you want to use to select the model (`refit='f1'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the XGBoost classifier\n",
    "xgb = XGBClassifier(random_state=42, objective='binary:logistic')\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "# 3. Define a dictionary of scoring metrics to capture\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "xgb_cv = GridSearchCV(xgb, \n",
    "                      param_grid=params, \n",
    "                      scoring=scoring, \n",
    "                      n_jobs=-1, \n",
    "                      cv=5, \n",
    "                      refit='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the model to the `X_train` and `y_train` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22.3 s\n",
      "Wall time: 15min 46s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7], &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7], &#x27;min_child_weight&#x27;: [1, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             refit=&#x27;f1&#x27;, scoring=[&#x27;accuracy&#x27;, &#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;f1&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=42, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 7], 'min_child_weight': [1, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             refit='f1', scoring=['accuracy', 'precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best score from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518549670456254"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "xgb_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bB-QyGz0RcU"
   },
   "source": [
    "And the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JiLja3YViTzj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best parameters\n",
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTE2QdNP0eEP"
   },
   "source": [
    "XGB CV Results\n",
    "\n",
    "Use the `make_results()` function to output all of the scores of your model. Note that it accepts three arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "L4TSYXJWiTxs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned XGBoost CV</td>\n",
       "      <td>0.69606</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>0.751855</td>\n",
       "      <td>0.714053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  precision    recall        F1  accuracy\n",
       "0  Tuned XGBoost CV    0.69606  0.817493  0.751855  0.714053"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "result3 = make_results('Tuned XGBoost CV', xgb_cv, 'accuracy')\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR1QdIAX1dKX"
   },
   "source": [
    "Use your model to predict on the test data. Assign the results to a variable called `preds`.\n",
    "\n",
    "<details>\n",
    "  <summary><h5>HINT</h5></summary>\n",
    "    \n",
    "You cannot call `predict()` on the GridSearchCV object directly. You must call it on the `best_estimator_`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "5Y2giCN32Dwc"
   },
   "outputs": [],
   "source": [
    "# Get scores on test data\n",
    "preds = xgb_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEwnNMMP2Nbb"
   },
   "source": [
    "###### XGB test results\n",
    "\n",
    "1. Use the `get_test_scores()` function to generate the scores on the test data. Assign the results to `xgb_test_scores`.\n",
    "2. Call `xgb_test_scores` to output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "g7jShC2TiTvx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned XGBoost CV (Test)</td>\n",
       "      <td>0.673251</td>\n",
       "      <td>0.806266</td>\n",
       "      <td>0.733779</td>\n",
       "      <td>0.700295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  precision    recall        F1  accuracy\n",
       "0  Tuned XGBoost CV (Test)   0.673251  0.806266  0.733779  0.700295"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get scores on test data\n",
    "result4 = get_test_scores('Tuned XGBoost CV (Test)', preds, y_test)\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Random Forest CV</td>\n",
       "      <td>0.696253</td>\n",
       "      <td>0.817184</td>\n",
       "      <td>0.751833</td>\n",
       "      <td>0.714135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Random Forest CV (Test)</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0.806266</td>\n",
       "      <td>0.733993</td>\n",
       "      <td>0.700622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned XGBoost CV</td>\n",
       "      <td>0.696060</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>0.751855</td>\n",
       "      <td>0.714053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned XGBoost CV (Test)</td>\n",
       "      <td>0.673251</td>\n",
       "      <td>0.806266</td>\n",
       "      <td>0.733779</td>\n",
       "      <td>0.700295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  precision    recall        F1  accuracy\n",
       "0         Tuned Random Forest CV   0.696253  0.817184  0.751833  0.714135\n",
       "0  Tuned Random Forest CV (Test)   0.673611  0.806266  0.733993  0.700622\n",
       "0               Tuned XGBoost CV   0.696060  0.817493  0.751855  0.714053\n",
       "0        Tuned XGBoost CV (Test)   0.673251  0.806266  0.733779  0.700295"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([result, result3, result4], axis=0)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saM8YwbAyi-F"
   },
   "source": [
    "**Question:** Compare these scores to the random forest test scores. What do you notice? Which model would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the tuned random forest model has slightly better performance than the XGBoost model. However, the difference in performance is not significant. If I had to choose one model, I would choose the tuned random forest model because it has slightly better performance on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCNH80Ku9TpO"
   },
   "source": [
    "Plot a confusion matrix of the model's predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "5iUyZWjWvqOd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_rf_model = rf_cv.best_estimator_\n",
    "\n",
    "# Generate array of values for confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot = ConfusionMatrixDisplay(cm, display_labels=best_rf_model.classes_)\n",
    "plot.plot(cmap='Blues', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW-3_eWW-k2u"
   },
   "source": [
    "**Question:** What type of errors are more common for your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positives** is more common with our model, double as **False Negatives**, meaning Type I error is prevailing.\n",
    "\n",
    "Our model is more prone to **False Positives** (predicting a generous tip when it's actually not), it means it's often predicting positive outcomes that turn out to be incorrect. This could lead to potential misunderstandings or dissatisfaction among taxi drivers if they expect larger tips based on the model's prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNexnwvy09PK"
   },
   "source": [
    "##### **Feature importance**\n",
    "\n",
    "Use the `plot_importance` function to inspect the top 10 most important features of your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "kz5T1gHc1R2x"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(xgb_cv.best_estimator_, \n",
    "                title='Top 10 Important Features', \n",
    "                max_num_features=10, \n",
    "                grid=False, \n",
    "                height=0.5)\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HGsWfEOeWPm"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Execute**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Execute stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ill21hQ4ej9-"
   },
   "source": [
    "### **Task 4. Conclusion**\n",
    "\n",
    "In this step, use the results of the models above to formulate a conclusion. Consider the following questions:\n",
    "\n",
    "1. **Would you recommend using this model? Why or why not?**  \n",
    "→ No, the accuracy of the model is still not so high. For me, at least, 85% accuracy would be good enough and I want to balance between FP and FN. In this model, accuracy using Random Forest and XGBoost is only 70% and there are a lot of of predictive variables (more than 300) so PCA is needed to lower the dimensitivity of the model.\n",
    "2. **What was your model doing? Can you explain how it was making predictions?**   \n",
    "→ Unfortunately, XGBoost is not the most transparent machine learning algorithm. We know that `predicted_fare`, `mean_duration`, and `mean_distance` are the most important features, but we don't know how they influence tipping. This would require further exploration.\n",
    "3. **Are there new features that you can engineer that might improve model performance?**   \n",
    "→ There are almost always additional features that can be engineered, but hopefully the most obvious ones were generated during the first round of modeling. In our case, we could try creating three new columns that indicate if the trip distance is short, medium, or far. We could also engineer a column that gives a ratio that represents (the amount of money from the fare amount to the nearest higher multiple of $5) / fare amount. For example, if the fare were \\\\$12, the value in this column would be 0.25, because \\\\$12 to the nearest higher multiple of \\\\$5 (\\\\$15) is \\\\$3, and \\\\$3 divided by \\\\$12 is 0.25. The intuition for this feature is that people might be likely to simply round up their tip, so journeys with fares with values just under a multiple of \\\\$5 may have lower tip percentages than those with fare values just over a multiple of \\\\$5. We could also do the same thing for fares to the nearest \\\\$10.\n",
    "\n",
    "4. **What features would you want to have that would likely improve the performance of your model?**   \n",
    "→ It would probably be very helpful to have past tipping behavior for each customer. It would also be valuable to have accurate tip values for customers who pay with cash. It would be helpful to have a lot more data. With enough data, we could create a unique feature for each pickup/dropoff combination.\n",
    "\n",
    "Remember, sometimes your data simply will not be predictive of your chosen target. This is common. Machine learning is a powerful tool, but it is not magic. If your data does not contain predictive signal, even the most complex algorithm will not be able to deliver consistent and accurate predictions. Do not be afraid to draw this conclusion. Even if you cannot use the model to make strong predictions, was the work done in vain? Consider any insights that you could report back to stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1oNheYh5WbljxkvoK_BMkQTey2DWnFXMs",
     "timestamp": 1663785370813
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
